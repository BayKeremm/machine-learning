{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot\n",
    "from scipy import optimize\n",
    "from scipy.io import loadmat\n",
    "from sklearn.preprocessing import OneHotEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_train = \"../archive/poker-hand-training.csv\"\n",
    "path_test = \"../archive/poker-hand-testing.csv\"\n",
    "\n",
    "train_data = pd.read_csv(path_train)\n",
    "test_data = pd.read_csv(path_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Suit of Card 1</th>\n",
       "      <th>Rank of Card 1</th>\n",
       "      <th>Suit of Card 2</th>\n",
       "      <th>Rank of Card 2</th>\n",
       "      <th>Suit of Card 3</th>\n",
       "      <th>Rank of Card 3</th>\n",
       "      <th>Suit of Card 4</th>\n",
       "      <th>Rank of Card 4</th>\n",
       "      <th>Suit of Card 5</th>\n",
       "      <th>Rank of Card 5</th>\n",
       "      <th>Poker Hand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Suit of Card 1  Rank of Card 1  Suit of Card 2  Rank of Card 2  \\\n",
       "0               1              10               1              11   \n",
       "1               2              11               2              13   \n",
       "2               3              12               3              11   \n",
       "3               4              10               4              11   \n",
       "4               4               1               4              13   \n",
       "\n",
       "   Suit of Card 3  Rank of Card 3  Suit of Card 4  Rank of Card 4  \\\n",
       "0               1              13               1              12   \n",
       "1               2              10               2              12   \n",
       "2               3              13               3              10   \n",
       "3               4               1               4              13   \n",
       "4               4              12               4              11   \n",
       "\n",
       "   Suit of Card 5  Rank of Card 5  Poker Hand  \n",
       "0               1               1           9  \n",
       "1               2               1           9  \n",
       "2               3               1           9  \n",
       "3               4              12           9  \n",
       "4               4              10           9  "
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.columns = [\"SuitCard1\",\"RC1\", \"SuitCard2\",\"RC2\",\"SuitCard3\",\"RC3\",\"SuitCard4\",\"RC4\",\"SuitCard5\", \"RC5\",\"PH\"]\n",
    "test_data.columns = [\"SuitCard1\",\"RC1\", \"SuitCard2\",\"RC2\",\"SuitCard3\",\"RC3\",\"SuitCard4\",\"RC4\",\"SuitCard5\", \"RC5\",\"PH\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train_data.drop(\"PH\", axis = 1).to_numpy()\n",
    "train_y = train_data.PH.to_numpy()\n",
    "\n",
    "test_x = test_data.drop(\"PH\", axis = 1).to_numpy()\n",
    "test_y = test_data.PH.to_numpy()\n",
    "\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "train_y_onehot = encoder.fit_transform(np.reshape(train_y,(-1,1)))\n",
    "test_y_onehot = encoder.fit_transform(np.reshape(test_y,(-1,1)))\n",
    "train_x_onehot = encoder.fit_transform(np.reshape(train_x,(-1,1)))\n",
    "test_x_onehot = encoder.fit_transform(np.reshape(test_x,(-1,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "print(train_y[0])\n",
    "print(train_y_onehot[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    \"\"\"\n",
    "    Computes the sigmoid of z.\n",
    "    \"\"\"\n",
    "    return 1.0 / (1.0 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoidGradient(z):\n",
    "    g = np.zeros(z.shape)\n",
    "\n",
    "    g = sigmoid(z)*(1-sigmoid(z))\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer_size = 10\n",
    "hidden_layer_size1 = 50\n",
    "hidden_layer_size2 = 30\n",
    "num_labels = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nnCostFunction(nn_params,\n",
    "                   input_layer_size,\n",
    "                   hidden_layer_size1,\n",
    "                   hidden_layer_size2,\n",
    "                   num_labels,\n",
    "                   X, y, lambda_=0.0):\n",
    "    # Reshape nn_params back into the parameters Theta1 and Theta2, the weight matrices\n",
    "    # for our 2 layer neural network\n",
    "    Theta1 = np.reshape(nn_params[:hidden_layer_size1 * (input_layer_size + 1)],\n",
    "                        (hidden_layer_size1, (input_layer_size + 1)))\n",
    "\n",
    "    Theta2 = np.reshape(nn_params[(hidden_layer_size1 * (input_layer_size + 1)):((hidden_layer_size1 * (input_layer_size + 1)) + (hidden_layer_size2 * (hidden_layer_size1+1)))],\n",
    "                        (hidden_layer_size2, (hidden_layer_size1 + 1)))\n",
    "    Theta3 = np.reshape(nn_params[(hidden_layer_size2 * (hidden_layer_size1 + 1)+(hidden_layer_size1 * (input_layer_size + 1))):],\n",
    "                        (num_labels, (hidden_layer_size2 + 1)))\n",
    "    # Setup some useful variables\n",
    "    m = y.shape[0]\n",
    "         \n",
    "    # You need to return the following variables correctly \n",
    "    J = 0\n",
    "    Theta1_grad = np.zeros(Theta1.shape)\n",
    "    Theta2_grad = np.zeros(Theta2.shape)\n",
    "    Theta3_grad = np.zeros(Theta3.shape)\n",
    "\n",
    "    # ====================== YOUR CODE HERE ======================\n",
    "    a1 = np.concatenate([np.ones((m, 1)), X], axis=1)\n",
    "    \n",
    "    a2 = sigmoid(a1.dot(Theta1.T))\n",
    "    a2 = np.concatenate([np.ones((a2.shape[0], 1)), a2], axis=1)\n",
    "    \n",
    "    a3 = sigmoid(a2.dot(Theta2.T))\n",
    "    a3 = np.concatenate([np.ones((a3.shape[0], 1)), a3], axis=1)\n",
    "\n",
    "    a4 = sigmoid(a3.dot(Theta3.T))\n",
    "    \n",
    "    y_matrix = y.reshape(-1)\n",
    "    y_matrix = np.eye(num_labels)[y_matrix]\n",
    "    \n",
    "    temp1 = Theta1\n",
    "    temp2 = Theta2\n",
    "    temp3 = Theta3\n",
    "    \n",
    "    # Add regularization term\n",
    "    \n",
    "    reg_term = (lambda_ / (2 * m)) * (np.sum(np.square(temp1[:, 1:])) + np.sum(np.square(temp2[:, 1:])) +np.sum(np.square(temp3[:, 1:])) )\n",
    "    \n",
    "    J = (-1 / m) * np.sum((np.log(a4) * y_matrix) + np.log(1 - a4) * (1 - y_matrix)) + reg_term\n",
    "    \n",
    "    # Backpropogation\n",
    "    \n",
    "    delta_4 = a4 - y_matrix\n",
    "    delta_3 = delta_4.dot(Theta3)[:, 1:] * sigmoidGradient(a2.dot(Theta2.T))\n",
    "    delta_2 = delta_3.dot(Theta2)[:, 1:] * sigmoidGradient(a1.dot(Theta1.T))\n",
    "\n",
    "    Delta1 = delta_2.T.dot(a1)\n",
    "    Delta2 = delta_3.T.dot(a2)\n",
    "    Delta3 = delta_4.T.dot(a3)\n",
    "    \n",
    "    # Add regularization to gradient\n",
    "\n",
    "    Theta1_grad = (1 / m) * Delta1\n",
    "    Theta1_grad[:, 1:] = Theta1_grad[:, 1:] + (lambda_ / m) * Theta1[:, 1:]\n",
    "    \n",
    "    Theta2_grad = (1 / m) * Delta2\n",
    "    Theta2_grad[:, 1:] = Theta2_grad[:, 1:] + (lambda_ / m) * Theta2[:, 1:]\n",
    "\n",
    "    Theta3_grad = (1 / m) * Delta3\n",
    "    Theta3_grad[:, 1:] = Theta3_grad[:, 1:] + (lambda_ / m) * Theta3[:, 1:]\n",
    "\n",
    "    grad = np.concatenate([Theta1_grad.ravel(), Theta2_grad.ravel(), Theta3_grad.ravel()])\n",
    "\n",
    "    return J, grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randInitializeWeights(L_in, L_out, epsilon_init=0.12):\n",
    "    W = np.zeros((L_out, 1 + L_in))\n",
    "    W = np.random.rand(L_out, 1 + L_in) * 2 * epsilon_init - epsilon_init\n",
    "    return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Neural Network Parameters ...\n",
      "(50, 11)\n",
      "(30, 51)\n",
      "(10, 31)\n",
      "(550,)\n",
      "(1530,)\n",
      "(310,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2390,)"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Initializing Neural Network Parameters ...')\n",
    "\n",
    "initial_Theta1 = randInitializeWeights(input_layer_size, hidden_layer_size1)\n",
    "initial_Theta2 = randInitializeWeights(hidden_layer_size1, hidden_layer_size2)\n",
    "initial_Theta3 = randInitializeWeights(hidden_layer_size2, num_labels)\n",
    "print(initial_Theta1.shape)\n",
    "print(initial_Theta2.shape)\n",
    "print(initial_Theta3.shape)\n",
    "\n",
    "# Unroll parameters\n",
    "print(initial_Theta1.ravel().shape)\n",
    "print(initial_Theta2.ravel().shape)\n",
    "print(initial_Theta3.ravel().shape)\n",
    "initial_nn_params = np.concatenate([initial_Theta1.ravel(), initial_Theta2.ravel(), initial_Theta3.ravel()], axis=0)\n",
    "initial_nn_params.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(550,)\n",
      "(30, 51)\n",
      "(10, 31)\n"
     ]
    }
   ],
   "source": [
    "Theta1 = np.reshape(initial_nn_params[:hidden_layer_size1 * (input_layer_size + 1)],\n",
    "                    (hidden_layer_size1, (input_layer_size + 1)))\n",
    "\n",
    "Theta2 = np.reshape(initial_nn_params[(hidden_layer_size1 * (input_layer_size + 1)):((hidden_layer_size1 * (input_layer_size + 1)) + (hidden_layer_size2 * (hidden_layer_size1+1)))],\n",
    "                    (hidden_layer_size2, (hidden_layer_size1 + 1)))\n",
    "Theta3 = np.reshape(initial_nn_params[(hidden_layer_size2 * (hidden_layer_size1 + 1)+(hidden_layer_size1 * (input_layer_size + 1))):],\n",
    "                    (num_labels, (hidden_layer_size2 + 1)))\n",
    "\n",
    "print(Theta1.ravel().shape)\n",
    "print(Theta2.shape)\n",
    "print(Theta3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pt/c3pppqgj6rx6ydqlk9zj4s1w0000gn/T/ipykernel_9836/2491853849.py:16: DeprecationWarning: 'maxiter' has been deprecated in favor of 'maxfun' and will be removed in SciPy 1.11.0.\n",
      "  res = optimize.minimize(costFunction,\n",
      "/var/folders/pt/c3pppqgj6rx6ydqlk9zj4s1w0000gn/T/ipykernel_9836/813485969.py:5: RuntimeWarning: overflow encountered in exp\n",
      "  return 1.0 / (1.0 + np.exp(-z))\n",
      "/var/folders/pt/c3pppqgj6rx6ydqlk9zj4s1w0000gn/T/ipykernel_9836/3202613678.py:47: RuntimeWarning: divide by zero encountered in log\n",
      "  J = (-1 / m) * np.sum((np.log(a4) * y_matrix) + np.log(1 - a4) * (1 - y_matrix)) + reg_term\n",
      "/var/folders/pt/c3pppqgj6rx6ydqlk9zj4s1w0000gn/T/ipykernel_9836/3202613678.py:47: RuntimeWarning: invalid value encountered in multiply\n",
      "  J = (-1 / m) * np.sum((np.log(a4) * y_matrix) + np.log(1 - a4) * (1 - y_matrix)) + reg_term\n"
     ]
    }
   ],
   "source": [
    "#  After you have completed the assignment, change the maxiter to a larger\n",
    "#  value to see how more training helps.\n",
    "options= {'maxiter': 500}\n",
    "\n",
    "#  You should also try different values of lambda\n",
    "lambda_ = 0\n",
    "\n",
    "# Create \"short hand\" for the cost function to be minimized\n",
    "costFunction = lambda p: nnCostFunction(p, input_layer_size,\n",
    "                                        hidden_layer_size1,\n",
    "                                        hidden_layer_size2,\n",
    "                                        num_labels, train_x, train_y, lambda_)\n",
    "\n",
    "# Now, costFunction is a function that takes in only one argument\n",
    "# (the neural network parameters)\n",
    "res = optimize.minimize(costFunction,\n",
    "                        initial_nn_params,\n",
    "                        jac=True,\n",
    "                        method='TNC',\n",
    "                        options=options)\n",
    "\n",
    "# get the solution of the optimization\n",
    "nn_params = res.x\n",
    "        \n",
    "# Obtain Theta1 and Theta2 back from nn_params\n",
    "Theta1 = np.reshape(nn_params[:hidden_layer_size1 * (input_layer_size + 1)],\n",
    "                    (hidden_layer_size1, (input_layer_size + 1)))\n",
    "\n",
    "Theta2 = np.reshape(nn_params[(hidden_layer_size1 * (input_layer_size + 1)):((hidden_layer_size1 * (input_layer_size + 1)) + (hidden_layer_size2 * (hidden_layer_size1+1)))],\n",
    "                    (hidden_layer_size2, (hidden_layer_size1 + 1)))\n",
    "Theta3 = np.reshape(nn_params[(hidden_layer_size2 * (hidden_layer_size1 + 1)+(hidden_layer_size1 * (input_layer_size + 1))):],\n",
    "                    (num_labels, (hidden_layer_size2 + 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(Theta1, Theta2,Theta3, X):\n",
    "    # Useful values\n",
    "    m = X.shape[0]\n",
    "    num_labels = Theta2.shape[0]\n",
    "\n",
    "    p = np.zeros(m)\n",
    "    h1 = sigmoid(np.dot(np.concatenate([np.ones((m, 1)), X], axis=1), Theta1.T))\n",
    "    h2 = sigmoid(np.dot(np.concatenate([np.ones((m, 1)), h1], axis=1), Theta2.T))\n",
    "    h3 = sigmoid(np.dot(np.concatenate([np.ones((m, 1)), h2], axis=1), Theta3.T))\n",
    "    p = np.argmax(h3, axis=1)\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Accuracy: 63.332600\n"
     ]
    }
   ],
   "source": [
    "pred = predict(Theta1, Theta2, Theta3,test_x)\n",
    "print('Training Set Accuracy: %f' % (np.mean(pred == test_y) * 100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('ml-masters')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "02d839075717808c242e78230290f9c44601d4eb3c3592dcf0040d4f25a8fdf1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
